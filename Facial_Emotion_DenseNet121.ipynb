{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PY9JGRfJMIQJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "UjEAia0FSQLm",
    "outputId": "fe8601dd-7f0f-42ee-b4ac-eae7499e6b57"
   },
   "outputs": [],
   "source": [
    "!pip install mlxtend\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CATEGORIES = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "X = []\n",
    "y = []\n",
    "data = pd.read_csv(r'H:\\Facial Emotion Recognition\\Dataset\\FER2013\\fer2013.csv')  # Remove the extra double quotes\n",
    "# Check data shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_map = {0: 'Angry', 1: 'Digust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "emotion_counts = data['emotion'].value_counts(sort=False).reset_index()\n",
    "emotion_counts.columns = ['emotion', 'number']\n",
    "emotion_counts['emotion'] = emotion_counts['emotion'].map(emotion_map)\n",
    "emotion_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming that emotion_counts is a DataFrame with columns 'emotion' and 'number'\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(data=emotion_counts, x='emotion', y='number')\n",
    "plt.title('Class distribution')\n",
    "plt.ylabel('Number', fontsize=12)\n",
    "plt.xlabel('Emotions', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    try:\n",
    "        pixels=np.asarray(list(row['pixels'].split(' ')), dtype=np.uint8)\n",
    "        img = pixels.reshape((48,48))\n",
    "        X.append(img)\n",
    "        y.append(row['emotion'])\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "for counter, img in enumerate(X[:12]):\n",
    "    ax = fig.add_subplot(3, 4, counter + 1)\n",
    "    ax.imshow(X[counter], cmap='gray')\n",
    "    plt.title(CATEGORIES[y[counter]])\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X, dtype='float32').reshape(-1, 48, 48)\n",
    "rgb_X = np.repeat(X[..., np.newaxis], 3, -1)\n",
    "rgb_X=rgb_X/255.\n",
    "y = np.asarray(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_val, y_train, y_val) = train_test_split(rgb_X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=2022,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "generator_val = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_train.fit(X_train)\n",
    "\n",
    "generator_val.fit(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(CATEGORIES), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint to save the best model weights\n",
    "checkpoint = ModelCheckpoint(\"emotion_detection_densenet.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Reduce learning rate if validation loss plateaus\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    aug_train.flow(X_train, y_train, batch_size=64),\n",
    "    validation_data=generator_val.flow(X_val, y_val, batch_size=64),\n",
    "    steps_per_epoch=len(X_train) // 64,\n",
    "    validation_steps=len(X_val) // 64,\n",
    "    epochs=25,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "c \n",
    "# Plot training & validation accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate predictions on the validation set\n",
    "predicted_labels = model.predict(X_val)\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CATEGORIES, yticklabels=CATEGORIES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "y_pred_probs = model.predict(X_val)\n",
    "\n",
    "# Convert y_val to one-hot encoded format\n",
    "y_val_one_hot = np.zeros((len(y_val), len(CATEGORIES)))\n",
    "y_val_one_hot[np.arange(len(y_val)), y_val] = 1\n",
    "\n",
    "# Calculate ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_val_one_hot, y_pred_probs, average='macro')\n",
    "\n",
    "# Calculate Average Precision (AP) Score\n",
    "ap_score = average_precision_score(y_val_one_hot, y_pred_probs, average='macro')\n",
    "\n",
    "print(f'ROC-AUC Score: {roc_auc}')\n",
    "print(f'Average Precision Score: {ap_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = y_val.astype(int)\n",
    "\n",
    "class_report = classification_report(y_true, y_pred_classes, target_names=CATEGORIES)\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning and more aggressive data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# Define a learning rate schedule (e.g., using ReduceLROnPlateau)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Hyperparameter tuning: Adjust learning rate and batch size\n",
    "learning_rate = 0.001  # Start with a reasonable learning rate\n",
    "batch_size = 64  # Start with a reasonable batch size\n",
    "\n",
    "# Define a more aggressive data augmentation configuration\n",
    "aug_train = ImageDataGenerator(\n",
    "    rotation_range=30,  # Increase the rotation range\n",
    "    zoom_range=0.3,  # Increase the zoom range\n",
    "    width_shift_range=0.3,  # Increase the width shift range\n",
    "    height_shift_range=0.3,  # Increase the height shift range\n",
    "    shear_range=0.3,  # Increase the shear range\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "# Compile the model with the chosen learning rate\n",
    "model.compile(optimizer=Adam(lr=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the chosen batch size and data augmentation\n",
    "history = model.fit(\n",
    "    aug_train.flow(X_train, y_train, batch_size=batch_size),\n",
    "    validation_data=generator_val.flow(X_val, y_val, batch_size=batch_size),\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    validation_steps=len(X_val) // batch_size,\n",
    "    epochs=50,\n",
    "    callbacks=[reduce_lr]  # You can keep the same callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy and loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate predictions on the validation set\n",
    "predicted_labels = model.predict(X_val)\n",
    "predicted_labels = np.argmax(predicted_labels, axis=1)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_val, predicted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CATEGORIES, yticklabels=CATEGORIES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "y_pred_probs = model.predict(X_val)\n",
    "\n",
    "# Convert y_val to one-hot encoded format\n",
    "y_val_one_hot = np.zeros((len(y_val), len(CATEGORIES)))\n",
    "y_val_one_hot[np.arange(len(y_val)), y_val] = 1\n",
    "\n",
    "# Calculate ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_val_one_hot, y_pred_probs, average='macro')\n",
    "\n",
    "# Calculate Average Precision (AP) Score\n",
    "ap_score = average_precision_score(y_val_one_hot, y_pred_probs, average='macro')\n",
    "\n",
    "print(f'ROC-AUC Score: {roc_auc}')\n",
    "print(f'Average Precision Score: {ap_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = y_val.astype(int)\n",
    "\n",
    "class_report = classification_report(y_true, y_pred_classes, target_names=CATEGORIES)\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
